{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IKE-Emma/ChatBot-/blob/main/intellegent_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hveNOm-ZgNH",
        "outputId": "6c70568f-9dd9-4f6b-f93e-c0d5c7469b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import random\n",
        "import string\n",
        "import re, string, unicodedata\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import wikipedia as wk\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('punkt') \n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLnvQVHzZgNY"
      },
      "outputs": [],
      "source": [
        "data = open('constitution.txt','r',errors = 'ignore')\n",
        "raw = data.read()\n",
        "raw = raw.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Oo4aEr0hZgNZ",
        "outputId": "fe8e80ed-411b-4109-b806-5635e4941bd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'federal republic of nigeria\\n\\n \\n\\n1. (1) this constitution is supreme and its provisions shall have binding force on the authorities and persons throughout the federal republic of nigeria.\\n\\n(2) the federal republic of nigeria shall not be governed, nor shall any persons or group of persons take control of the government of nigeria or any part thereof, except in accordance with the provisions of this constitution.\\n\\n(3) if any other law is inconsistent with the provisions of this constitution, this constitution shall prevail, and that other law shall, to the extent of the inconsistency, be void.\\n\\n2. (1) nigeria is one indivisible and indissoluble sovereign state to be known by the name of the federal republic of nigeria.\\n\\n(2) nigeria shall be a federation consisting of states and a federal capital territory.\\n\\n3. (1) there shall be 36 states in nigeria, that is to say, abia, adamawa, akwa ibom, anambra, bauchi, bayelsa, benue, borno, cross river, delta, ebonyi, edo, ekiti, enugu, gombe, imo'"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "raw[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcaC585IZgNa"
      },
      "outputs": [],
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOigl02yZgNa"
      },
      "outputs": [],
      "source": [
        "def Normalize(text):\n",
        "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "    #word tokenization\n",
        "    word_token = nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n",
        "    \n",
        "    #remove ascii\n",
        "    new_words = []\n",
        "    for word in word_token:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    \n",
        "    #Remove tags\n",
        "    rmv = []\n",
        "    for w in new_words:\n",
        "        text=re.sub(\"&lt;/?.*?&gt;\",\"&lt;&gt;\",w)\n",
        "        rmv.append(text)\n",
        "        \n",
        "    #pos tagging and lemmatization\n",
        "    tag_map = defaultdict(lambda : wn.NOUN)\n",
        "    tag_map['J'] = wn.ADJ\n",
        "    tag_map['V'] = wn.VERB\n",
        "    tag_map['R'] = wn.ADV\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    lemma_list = []\n",
        "    rmv = [i for i in rmv if i]\n",
        "    for token, tag in nltk.pos_tag(rmv):\n",
        "        lemma = lmtzr.lemmatize(token, tag_map[tag[0]])\n",
        "        lemma_list.append(lemma)\n",
        "    return lemma_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5Nc8Jn-ZgNb"
      },
      "outputs": [],
      "source": [
        "welcome_input = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "welcome_response = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def welcome(user_response):\n",
        "    for word in user_response.split():\n",
        "        if word.lower() in welcome_input:\n",
        "            return random.choice(welcome_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDvL52k9ZgNc"
      },
      "outputs": [],
      "source": [
        "def generateResponse(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=Normalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    # vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    vals = linear_kernel(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0) or \"tell me about\" in user_response:\n",
        "        print(\"Checking Wikipedia\")\n",
        "        if user_response:\n",
        "            robo_response = wikipedia_data(user_response)\n",
        "            return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response#wikipedia search\n",
        "def wikipedia_data(input):\n",
        "    reg_ex = re.search('tell me about (.*)', input)\n",
        "    try:\n",
        "        if reg_ex:\n",
        "            topic = reg_ex.group(1)\n",
        "            wiki = wk.summary(topic, sentences = 1000)\n",
        "            return wiki\n",
        "    except Exception as e:\n",
        "            print(\"No content has been found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9sAYJgYZgNd",
        "outputId": "9e23a285-aefb-4b1d-ca54-caa1d1cf2c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Chatterbot and I'm a chatbot. If you want to exit, type Bye!\n",
            "the National Assembly\n",
            "Chatterbot : (3) where a member of a house of assembly or of the national assembly is appointed as commissioner of the government of a state, he shall be deemed to have resigned his membership of the house of assembly or of the national assembly on his taking the oath of office as commissioner.\n",
            "bye\n",
            "Chatterbot : Bye!!! \n"
          ]
        }
      ],
      "source": [
        "flag=True\n",
        "print(\"My name is Chatterbot and I'm a chatbot. If you want to exit, type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response not in ['bye','shutdown','exit', 'quit']):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"Chatterbot : You are welcome..\")\n",
        "        else:\n",
        "            if(welcome(user_response)!=None):\n",
        "                print(\"Chatterbot : \"+welcome(user_response))\n",
        "            else:\n",
        "                print(\"Chatterbot : \",end=\"\")\n",
        "                print(generateResponse(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"Chatterbot : Bye!!! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDfF6EWQZgNe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ChatterBot.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}